{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Tutorial 2: Introduction to RNNs\n",
    "\n",
    "**Week 2, Day 1: Convnets And Recurrent Neural Networks**\n",
    "\n",
    "**By Neuromatch Academy**\n",
    "\n",
    "__Content creators:__ Dawn McKnight, Richard Gerum, Cassidy Pirlot, Rohan Saha, Liam Peet-Pare, Saeed Najafi, Alona Fyshe\n",
    "\n",
    "__Content reviewers:__ Saeed Salehi, Lily Cheng, Yu-Fang Yang, Polina Turishcheva, Nina Kudryashova, Kelson Shilling-Scrivo\n",
    "\n",
    "__Content editors:__ Nina Kudryashova\n",
    "\n",
    "__Production editors:__ Anmol Gupta, Spiros Chavlis \n",
    "\n",
    "*Based on material from:* Konrad Kording, Hmrishav Bandyopadhyay, Rahul Shekhar, Tejas Srivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs**\n",
    "\n",
    "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Tutorial Objectives\n",
    "At the end of this tutorial, we will be able to:\n",
    "- Understand the structure of a Recurrent Neural Network (RNN)\n",
    "- Build a simple RNN model\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Tutorial slides\n",
    "\n",
    "# @markdown These are the slides for the videos in this tutorial\n",
    "\n",
    "# @markdown If you want to download locally the slides, click [here](https://osf.io/5asx2/download)\n",
    "from IPython.display import IFrame\n",
    "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/5asx2/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.2.0-py2.py3-none-any.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# @title Install dependencies\n",
    "!pip install livelossplot --quiet\n",
    "!pip install unidecode\n",
    "\n",
    "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
    "from evaltools.airtable import AirtableForm\n",
    "\n",
    "# generate airtable form\n",
    "atform = AirtableForm('appn7VdPRseSoMXEG','W2D1_T2','https://portal.neuromatchacademy.org/api/redirect/to/351ca652-13d8-4e31-be28-30153d03e639')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinize@acct.upmchs.net/anaconda3/envs/Buzznauts/lib/python3.7/site-packages/ipykernel_launcher.py:6: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.legacy_colorbar rcparam was deprecated in Matplotlib 3.4 and will be removed two minor releases later.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# @title Figure settings\n",
    "import ipywidgets as widgets       # interactive display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle\")\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "\n",
    "def read_file(filename):\n",
    "  file = unidecode.unidecode(open(filename).read())\n",
    "  return file, len(file)\n",
    "\n",
    "\n",
    "# Turning a string into a tensor\n",
    "def char_tensor(string):\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "    try:\n",
    "      tensor[c] = all_characters.index(string[c])\n",
    "    except:\n",
    "      continue\n",
    "  return tensor\n",
    "\n",
    "\n",
    "# Readable time elapsed\n",
    "def time_since(since):\n",
    "  s = time.time() - since\n",
    "  m = math.floor(s / 60)\n",
    "  s -= m * 60\n",
    "  out = f\"{m}min {s}sec\"\n",
    "  return out\n",
    "\n",
    "\n",
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8,\n",
    "             device='cpu'):\n",
    "\n",
    "  hidden = decoder.init_hidden(1)\n",
    "  prime_input = char_tensor(prime_str).unsqueeze(0)\n",
    "\n",
    "  hidden = hidden.to(device)\n",
    "  prime_input = prime_input.to(device)\n",
    "  predicted = prime_str\n",
    "\n",
    "  # Use priming string to \"build up\" hidden state\n",
    "  for p in range(len(prime_str) - 1):\n",
    "    _, hidden = decoder(prime_input[:,p], hidden)\n",
    "\n",
    "  inp = prime_input[:,-1]\n",
    "\n",
    "  for p in range(predict_len):\n",
    "    output, hidden = decoder(inp, hidden)\n",
    "\n",
    "    # Sample from the network as a multinomial distribution\n",
    "    output_dist = output.data.view(-1).div(temperature).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "    # Add predicted character to string and use as next input\n",
    "    predicted_char = all_characters[top_i]\n",
    "    predicted += predicted_char\n",
    "    inp = char_tensor(predicted_char).unsqueeze(0)\n",
    "    inp = inp.to(device)\n",
    "\n",
    "  return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Set random seed\n",
    "\n",
    "# @markdown Executing `set_seed(seed=seed)` you are setting the seed\n",
    "\n",
    "# for DL its critical to set the random seed so that students can have a\n",
    "# baseline to compare their results to expected results.\n",
    "# Read more here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "# Call `set_seed` function in the exercises to ensure reproducibility.\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Set device (GPU or CPU). Execute `set_device()`\n",
    "# especially if torch modules used.\n",
    "\n",
    "# inform the user if the notebook uses GPU or CPU.\n",
    "\n",
    "def set_device():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 2021 has been set.\n",
      "GPU is enabled in this notebook.\n"
     ]
    }
   ],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 1: Recurrent Neural Networks (RNNs)\n",
    "\n",
    "*Time estimate: ~20mins*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f838d7e799442508fb43b09e474f7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Video 1: RNNs\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1L44y1m7PP\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"PsZjS125lLs\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "# add event to airtable\n",
    "atform.add_event('Video 1: RNNs')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "RNNs are compact models that operate over timeseries, and have the ability to remember past input. They also save parameters by using the same weights at every time step.  If you've heard of Transformers, those models don't have this kind of temporal weight sharing, and so they are *much* larger.\n",
    "\n",
    "The code below is adapted from [this github repository](https://github.com/spro/char-rnn.pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "# https://github.com/spro/char-rnn.pytorch\n",
    "class CharRNN(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size,\n",
    "               model=\"gru\", n_layers=1):\n",
    "    \"\"\"\n",
    "    input_size: int\n",
    "      Size of the input layer.\n",
    "    hidden_size: int\n",
    "      Size of the hidden layers.\n",
    "    output_size: int\n",
    "      Size of the output layer.\n",
    "    model: string\n",
    "      `model` can take the values \"gru\", \"rnn\", \"lstm\". Default is \"gru\".\n",
    "    n_layers: int\n",
    "      Number of layers\n",
    "    \"\"\"\n",
    "    super(CharRNN, self).__init__()\n",
    "    self.model = model.lower()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "    if self.model == \"gru\":\n",
    "      self.rnn = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"lstm\":\n",
    "      self.rnn = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "    elif self.model == \"rnn\":\n",
    "      self.rnn = nn.RNN(hidden_size, hidden_size, n_layers)\n",
    "    self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, input, hidden):\n",
    "    batch_size = input.size(0)\n",
    "    encoded = self.encoder(input)\n",
    "    output, hidden = self.rnn(encoded.reshape(1, batch_size, -1), hidden)\n",
    "    output = self.decoder(output.reshape(batch_size, -1))\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size):\n",
    "    if self.model == \"lstm\":\n",
    "      return (torch.zeros(self.n_layers, batch_size, self.hidden_size), torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "\n",
    "    return torch.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This next section of code takes care of training the RNN on several of Mark Twain's books. In this short section, we won't dive into the code, but you'll get to learn a lot more about RNNs in a few days! For now, we are just going to observe the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Run Me to get the data\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D1_ConvnetsAndRecurrentNeuralNetworks/static/twain.txt'\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open('twain.txt', 'wb') as fd:\n",
    "  fd.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "One cool thing about RNNs is that they can be used to _generate_ language based on what the network sees during training. As the network makes predictions, instead of confirming of those predictions are correct against some training text, we just feed them back into the model as the next observed token.  Starting from a random vector for the hidden state, we can generate many original sentences! And what the network generates will reflect the text it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/spro/char-rnn.pytorch\n",
    "def random_training_set(file, file_len, chunk_len, batch_size,\n",
    "                        device='cpu', seed=0):\n",
    "  random.seed(seed)\n",
    "\n",
    "  inp = torch.LongTensor(batch_size, chunk_len).to(device)\n",
    "  target = torch.LongTensor(batch_size, chunk_len).to(device)\n",
    "\n",
    "  for bi in range(batch_size):\n",
    "    start_index = random.randint(0, file_len - chunk_len - 1)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    chunk = file[start_index:end_index]\n",
    "    inp[bi] = char_tensor(chunk[:-1])\n",
    "    target[bi] = char_tensor(chunk[1:])\n",
    "\n",
    "  return inp, target, chunk_len, batch_size, device\n",
    "\n",
    "\n",
    "def train(decoder, criterion, inp, target, chunk_len, batch_size, device):\n",
    "  hidden = decoder.init_hidden(batch_size)\n",
    "  decoder.zero_grad()\n",
    "  loss = 0\n",
    "\n",
    "  for c in range(chunk_len):\n",
    "    output, hidden = decoder(inp[:, c].to(device), hidden.to(device))\n",
    "    loss += criterion(output.reshape(batch_size, -1), target[:,c])\n",
    "\n",
    "  loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "  return loss.item() / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "First, let's load the text file, and define the model and its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading and un-unicode-encoding data\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "# load the text file\n",
    "file, file_len = read_file('twain.txt')\n",
    "\n",
    "# Hyperparams\n",
    "batch_size = 50\n",
    "chunk_len = 200\n",
    "model = \"rnn\"  # other options: `lstm`, `gru`\n",
    "\n",
    "n_layers = 2\n",
    "hidden_size = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Define the model, optimizer, and the loss criterion\n",
    "decoder = CharRNN(n_characters, hidden_size, n_characters,\n",
    "                  model=model, n_layers=n_layers)\n",
    "decoder.to(DEVICE)\n",
    "\n",
    "decoder_optimizer = torch.optim.Adagrad(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419596\n"
     ]
    }
   ],
   "source": [
    "print(file_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Let's try it! Run the code below. As the network trains, it will output samples of generated text every 25 epochs. Notice that as the training progresses, the model learns to spell short words, then learns to string some words together, and eventually can produce meaningful sentences (sometimes)! Keep in mind that this is a relatively small network, and doesn't employ some of the cool things you'll learn about later in the week (e.g., LSTMs, though you can change that in the code below by changing the value of the `model` variable if you wish!)\n",
    "\n",
    "After running the model, and observing the output, get together with your pod, and talk about what you noticed during training. Did your network produce anything interesting? Did it produce anything characteristic of Twain?  \n",
    "\n",
    "**Note:** training for the full 2000 epochs is likely to take a while, so you may need to stop it before it finishes. If you have time left, set `n_epochs` to 2000 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 2000 epochs...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a0c31bdd744e02b8e77922fccaa69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0min 8.1932373046875sec 2.5%) 2.1629]\n",
      "Whey\n",
      "aid the pond\n",
      "-\n",
      "kit was  not then; the list sow un oving the seas ane lonney hrind and higst to comron gris on teen woCg't we theares\n",
      "some ding then\n",
      "[0min 16.40858030319214sec 5.0%) 1.9460]\n",
      "Wher, blethen chasted the she nuld or do and gotsenresen and of and Tom The gut we'p the dand thep thesired whon\n",
      "aght and and beterndelly, and_\n",
      "way. I d\n",
      "[0min 24.578437328338623sec 7.5%) 1.9131]\n",
      "Wher. The didy. for for betand sone, but feppiout ingring.\"\n",
      "\n",
      "\"What in the some was geavelight ow, be all kenting no cometing, he had him;\n",
      "uple was comen\n",
      "[0min 32.79515600204468sec 10.0%) 1.8869]\n",
      "Whel. _Two, and hand her what woundeds spart stees.  I was know the the going and\n",
      "hack. I was the coulds the he well combion she pots me labdeng-and\n",
      "and\n",
      "[0min 41.008482456207275sec 12.5%) 1.8738]\n",
      "Whered most the was eefder is mentires. Tow head you but don an the kisp was from shere for you couldn't was do then says:\n",
      "\n",
      "\"Then that was went was arou\n",
      "[0min 49.212931871414185sec 15.0%) 1.7902]\n",
      "Why some, bod think they preation of the prot\n",
      "hadn't do ned call them and she never the flately man's feer come them of lay with to be and that where of\n",
      "[0min 57.39076280593872sec 17.5%) 1.7627]\n",
      "Whack and\n",
      "would find and han him sast they dranger my the take a air a body-urst or while, and bed timbody conlat it of they was her the tound dary and \n",
      "[1min 5.5608744621276855sec 20.0%) 1.7369]\n",
      "Where and laid his priving cappent, and can't know, had bradge desided of and mears hone over_--and sich, and sturt get five the this be of they, and Ge\n",
      "[1min 13.683382987976074sec 22.5%) 1.7472]\n",
      "When come was a lain't do the read of his see and feeth, and\n",
      "spart giend that day you got to paicuses, compordy so, took to with hal juggent. I mades, a\n",
      "[1min 21.855158805847168sec 25.0%) 1.6912]\n",
      "WhE\n",
      "The single with a still the\n",
      "pain high, and I don's hamper to teard it seapoted ite. I say what the it upress and he splacking to dight\n",
      "that peased t\n",
      "[1min 30.04744863510132sec 27.500000000000004%) 1.6896]\n",
      "What to the tood the whine the resande_ it of the wern the said--\n",
      "\n",
      "\"The barn't\n",
      "the pioul all the puting out again,\n",
      "withe' mound was seat when the preckl\n",
      "[1min 38.29741883277893sec 30.0%) 1.6589]\n",
      "What its ascapon your heart hould we comrand--that would 'et was a\n",
      "noken scable to sigting I goke\n",
      "\n",
      "\"Goom time as I went throud steast deniged---and can \n",
      "[1min 46.485246419906616sec 32.5%) 1.6142]\n",
      "Where was I hards and leton he done hard as to\n",
      "was a tried the wall say!  The which had be found to mey rewore he come on there hid baging agries?\" near\n",
      "[1min 54.67632436752319sec 35.0%) 1.6676]\n",
      "Whered for him so it ont, for the it is his trouble was pace and foonations and was I see time, but strable she was ery or ensing a biss he said:  Where\n",
      "[2min 2.7973756790161133sec 37.5%) 1.6385]\n",
      "Why, '_ Mut the prace that found the othan took of the talky and all before the may done bard condigution of the Canners was at house to for a starting \n",
      "[2min 10.940011739730835sec 40.0%) 1.6340]\n",
      "Wh was a didn't do me and the hove the Shinded no, time.  The told no only for it was drept, the little had fection wooked them done the it.  or I've of\n",
      "[2min 18.825534343719482sec 42.5%) 1.6178]\n",
      "Whispered with the King was through be to to put me so the poodles as the bed he said himself off\n",
      "curious at in home--you plain to see it I reckon was a\n",
      "[2min 26.479459524154663sec 45.0%) 1.6028]\n",
      "Where her from on the work. We\n",
      "wall that did\n",
      "be every browd with the face that the\n",
      "pretty undides only Jim just on deliver. It hoo'? \"I les were aday to\n",
      "[2min 34.65658378601074sec 47.5%) 1.6067]\n",
      "Where have, and ne?  Then who.  The him.  The boy expriver. What ain't \"Take hear a charget. Then he still and was a when this doom in the retter thing.\n",
      "[2min 42.87393832206726sec 50.0%) 1.5520]\n",
      "Where in the litched time to poor that peesed about-body, I'll did nother kney secain something and the changer, and you hear,\n",
      "and caller along to got s\n",
      "[2min 50.989402055740356sec 52.5%) 1.5936]\n",
      "White it boing the your all on it out of him in the done, out half a did on the pastances.  Miles and 'sted got most beckon night in a kind agoney, and \n",
      "[2min 59.22161626815796sec 55.00000000000001%) 1.6021]\n",
      "Where, but it was backed her face my last in his langer, driver-so hear or as ones, the\n",
      ".\n",
      "He was variturant way, what the the\n",
      "boor the king their ay luf\n",
      "[3min 7.440751075744629sec 57.49999999999999%) 1.5753]\n",
      "Where to the\n",
      "sort, but deatter and he don't sear--and all not to shave before hangs, for of lossed pretty turn days forcity and that the most ben out of\n",
      "[3min 15.643359661102295sec 60.0%) 1.6287]\n",
      "Where off. They axter the disabures is\n",
      "whispert to get at the had said to astive the most that a good tried fwiend, mutses the moverful of in the boy?  \n",
      "[3min 23.82106113433838sec 62.5%) 1.5971]\n",
      "Whous birst it old begun the expedself afinute the give feel over there was a rightic to the worted accoss and says just can in the told ears, and the\n",
      "s\n",
      "[3min 32.033693075180054sec 65.0%) 1.5418]\n",
      "White, he went to him in the evening to hour setten put the under as it was to wait would I've to the come and carpenest the side\n",
      "furnted, and the sille\n",
      "[3min 40.20148038864136sec 67.5%) 1.5509]\n",
      "Where what I got to last ham have a from the reaking to ghis one or botting on the boy and a man and orner to stakes the person--it. Because, any plain \n",
      "[3min 48.34847712516785sec 70.0%) 1.5298]\n",
      "Why\n",
      "stotuch with her it was behind. There come again, so they was a banchings, and take it down the true he the same country that son more and have; imm\n",
      "[3min 56.52434539794922sec 72.5%) 1.5542]\n",
      "Where was a command, coniss in the peased to the brother, statcher he had nothing of from his morsent of ruin if the people of his heawed a looked about\n",
      "[4min 4.721784830093384sec 75.0%) 1.4721]\n",
      "Why?\"\n",
      "\n",
      "\"The dump, or gave the thing up baring floke of in streass him and last'n to wo; a tiggless out. Dilling had had get right be it do hours. You kn\n",
      "[4min 12.970098495483398sec 77.5%) 1.5847]\n",
      "Wherely that at let the stopped out time, so or the fations?\"\n",
      "\n",
      "\"Did he had been the time of the roople; and had capt of a trunth the badow?\"\n",
      "\n",
      "\"Well, goo\n",
      "[4min 21.228275299072266sec 80.0%) 1.5361]\n",
      "Where looked out their mest the day up to care expeefor\n",
      "side which the with upon them all of the gathan lights and sorry and capped into the only they n\n",
      "[4min 29.490073680877686sec 82.5%) 1.5320]\n",
      "Where--I reckon if you want the\n",
      "books a-behand ablerent to was noble to soon to took the boys insical to give the still appear to, but a good to his sor\n",
      "[4min 37.724233865737915sec 85.0%) 1.5356]\n",
      "Whet him set\n",
      "so from I\n",
      "says to the minot you are sound up and sent all the way the light and the palace; he was alway she face enough to the way now me \n",
      "[4min 45.96075248718262sec 87.5%) 1.5302]\n",
      "Where was some and said:\n",
      "\n",
      "\"You aster the emberglands in she town had you had do it. I think being, because it fun himself the kinted to she dreeved the\n",
      "\n",
      "[4min 54.161439657211304sec 90.0%) 1.4917]\n",
      "Whered if he strong broke, and and shall, and said a homes and considered I corned me, to the dogs, she would do, off as the works.\n",
      "\n",
      "The whisp's in a pr\n",
      "[5min 2.3405888080596924sec 92.5%) 1.5486]\n",
      "Whit, you crust shward twengs school\n",
      "that into the sorry with the flower--and it is convant master. Then\n",
      "skeep,\n",
      "and you'll got his brass were to a bit i\n",
      "[5min 10.508885860443115sec 95.0%) 1.5280]\n",
      "Where it.  The King little ragrest to aster this back of the conses to she was souls musinest me seements, and ready of it, and love the mile of the dis\n",
      "[5min 18.71679663658142sec 97.5%) 1.5072]\n",
      "Whow with this\n",
      "hanged me, spot to be good store.\n",
      "\n",
      "And began to keep it all says, \"In a going the town en that voices and specadements; I would be this t\n",
      "[5min 26.947940349578857sec 100.0%) 1.5407]\n",
      "Where\n",
      "he things of the place you lipped the face of eyes and set at once off in\n",
      "the\n",
      "-in, too more they was at the boy;\n",
      "most as you can't do it to expens\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000   # initial was set to 2000\n",
    "\n",
    "print_every = 50  # frequency of printing the outputs\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "print(f\"Training for {n_epochs} epochs...\\n\")\n",
    "for epoch in tqdm(range(1, n_epochs + 1), position=0, leave=True):\n",
    "  loss = train(decoder, criterion,\n",
    "               *random_training_set(file, file_len, chunk_len, batch_size,\n",
    "                                    device=DEVICE, seed=epoch))\n",
    "  loss_avg += loss\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "    print(f\"[{time_since(start)} {epoch/n_epochs * 100}%) {loss:.4f}]\")\n",
    "    print(f\"{generate(decoder, prime_str='Wh', predict_len=150, device=DEVICE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now you can generate more examples using a trained model. Recall that `generate` takes the mentioned below arguments to work:\n",
    "\n",
    "```python\n",
    "generate(decoder, prime_str='A', predict_len=100, temperature=0.8, device='cpu')\n",
    "```\n",
    "\n",
    "Try it by yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where to come side, howed his heads, and sighty to get of the ketting to sten a saw another three they\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{generate(decoder, prime_str='Wh', predict_len=100, device=DEVICE)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Section 2: Power consumption in Deep Learning\n",
    "\n",
    "*Time estimate: ~20mins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Training NN models can be incredibly costly, both in actual money but also in power consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7d2b3100744aac9221ff16f4ed8cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(Output(), Output()), _titles={'0': 'Youtube', '1': 'Bilibili'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Video 2: Carbon Footprint of AI\n",
    "from ipywidgets import widgets\n",
    "\n",
    "out2 = widgets.Output()\n",
    "with out2:\n",
    "  from IPython.display import IFrame\n",
    "  class BiliVideo(IFrame):\n",
    "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
    "      self.id=id\n",
    "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
    "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
    "\n",
    "  video = BiliVideo(id=f\"BV1My4y1j7HJ\", width=854, height=480, fs=1)\n",
    "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
    "  display(video)\n",
    "\n",
    "out1 = widgets.Output()\n",
    "with out1:\n",
    "  from IPython.display import YouTubeVideo\n",
    "  video = YouTubeVideo(id=f\"as6C334LmRs\", width=854, height=480, fs=1, rel=0)\n",
    "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
    "  display(video)\n",
    "\n",
    "out = widgets.Tab([out1, out2])\n",
    "out.set_title(0, 'Youtube')\n",
    "out.set_title(1, 'Bilibili')\n",
    "\n",
    "# add event to airtable\n",
    "atform.add_event('Video 2: Carbon Footprint of AI')\n",
    "\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Take a few moments to chat with your pod about the following points:\n",
    "* Which societal costs of training do you find most compelling?\n",
    "* When is training an AI model worth the cost?  Who should make that decision?\n",
    "* Should there be additional taxes on energy costs for compute centers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "## Exercise 2: Calculate the carbon footprint that your pod generated today.\n",
    "\n",
    "You can use this [online calculator](https://mlco2.github.io/impact/#compute). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12195805863e40d2924edef41dc5044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Type your answer here and click on `Submit!`', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26da733a48f94d29b6da0e50a01341b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title Student Response\n",
    "from ipywidgets import widgets\n",
    "\n",
    "\n",
    "text=widgets.Textarea(\n",
    "   value='Type your answer here and click on `Submit!`',\n",
    "   placeholder='Type something',\n",
    "   description='',\n",
    "   disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Submit!\")\n",
    "\n",
    "display(text,button)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "   atform.add_answer('q1', text.value)\n",
    "   print(\"Submission successful!\")\n",
    "\n",
    "\n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "What a day!  We've learned a lot!  The basics of CNNs and RNNs, and how changes to architecture that allow models to parameter share can greatly reduce the size of the model.  We learned about convolution and pooling, as well as the basic idea behind RNNs.  To wrap up we thought about the impact of training large NN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "form",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <div>\n",
       "   <a href= \"https://portal.neuromatchacademy.org/api/redirect/to/351ca652-13d8-4e31-be28-30153d03e639?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzJEMV9UMiIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTYyODU0MjE0OC42NjI2MDI0fSwgeyJldmVudCI6ICJWaWRlbyAxOiBSTk5zIiwgInRzIjogMTYyODU0MjE0OS42MDA0MTYyfSwgeyJldmVudCI6ICJWaWRlbyAyOiBDYXJib24gRm9vdHByaW50IG9mIEFJIiwgInRzIjogMTYyODU0NDcxNC4zMzYzOTUzfSwgeyJldmVudCI6ICJ1cmwgZ2VuZXJhdGVkIiwgInRzIjogMTYyODU0NTYxMy41MTQ1MDR9XX0%3D\" target=\"_blank\">\n",
       "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\"\n",
       " alt=\"button link end of day Survey\" style=\"width:410px\"></a>\n",
       "   </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Airtable Submission Link\n",
    "from IPython import display as IPydisplay\n",
    "IPydisplay.HTML(\n",
    "   f\"\"\"\n",
    " <div>\n",
    "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
    "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\"\n",
    " alt=\"button link end of day Survey\" style=\"width:410px\"></a>\n",
    "   </div>\"\"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "W2D1_Tutorial2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
