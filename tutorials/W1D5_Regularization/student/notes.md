# Regularization Techniques

# Tutorial 1

Underfit - You fit the bias of the data
Overfit - You fit the noise (therefore the variance) of the data

Zhang, Bengio, Hardt, Recht, and Vinyalsn, 2017

From W1D2, sometimes the loss stay at one value and decreases in bumps, we may end up missing one of those "breakthrough" moments. Also, if our dataset is unbalanced (unfair), we may be optimized for particular classes.

# Tutorial 2

LASSO regularization fluctuates maybe becase the network alternates between decreasing weights and loss function.