# Regularization Techniques

# Tutorial 1

Underfit - You fit the bias of the data
Overfit - You fit the noise (therefore the variance) of the data

Zhang, Bengio, Hardt, Recht, and Vinyalsn, 2017

From W1D2, sometimes the loss stay at one value and decreases in bumps, we may end up missing one of those "breakthrough" moments. Also, if our dataset is unbalanced (unfair), we may be optimized for particular classes.

# Tutorial 2

LASSO regularization fluctuates maybe becase the network alternates between decreasing weights and loss function.

My understand is that we are on the road, and the optimizer is the type of car you drive and regularization defines the path you take.

